# -*- coding: utf-8 -*-
"""LAB 6

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12n7Pc5X_nV7g7IDN0qm3X2SVMb7HhENR

Implement a program on Adversarial training, tangent distance, tangent prop and
tangent classifier. [Any three to be implemented].
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras import Sequential, layers
from tensorflow.keras.datasets import fashion_mnist
import matplotlib.pyplot as plt

# --- Prepare small subset of Fashion-MNIST ---
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
n_sub, n_test = 1000, 200
x_train = x_train[:n_sub] / 255.0; y_train = y_train[:n_sub]
x_test  = x_test[:n_test]  / 255.0; y_test  = y_test[:n_test]

# --- Simple classifier builder (optionally include TangentProp noise layer) ---
class TangentProp(layers.Layer):
    def call(self, x):
        return x + tf.random.normal(tf.shape(x), stddev=0.1)

def create_model(use_tangent=False):
    seq = Sequential()
    if use_tangent:
        seq.add(TangentProp(input_shape=(28,28)))    # add random-perturbation layer
    seq.add(layers.Flatten(input_shape=(28,28) if not use_tangent else None))
    seq.add(layers.Dense(64, activation='relu'))
    seq.add(layers.Dense(10, activation='softmax'))
    seq.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return seq

# --- Adversarial example generator: random sign perturbation clipped to [0,1] ---
def generate_adversarial_examples(x, eps=0.1, seed=100):
    rng = np.random.RandomState(seed)
    perturb = np.sign(rng.randn(*x.shape))
    return np.clip(x + eps * perturb, 0, 1)

# --- Tangent-distance (nearest-neighbor) helper ---
def tangent_distance(a, b):
    return np.linalg.norm(a - b)

def tangent_nn_classifier(x_train, y_train, x_test):
    xt = x_train.reshape(len(x_train), -1)
    xs = x_test.reshape(len(x_test), -1)
    preds = []
    for x in xs:
        dists = np.linalg.norm(xt - x, axis=1)
        preds.append(y_train[np.argmin(dists)])
    return np.array(preds)

# --- Train adversarially augmented model ---
model_adv = create_model()
x_adv = generate_adversarial_examples(x_train)
x_comb = np.concatenate([x_train, x_adv])
y_comb = np.concatenate([y_train, y_train])
hist_adv = model_adv.fit(x_comb, y_comb, epochs=5, validation_data=(x_test, y_test), verbose=0)

# --- Train model with TangentProp regularization ---
model_tangent = create_model(use_tangent=True)
hist_tp = model_tangent.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), verbose=0)

# --- Evaluate TangentProp model ---
loss_tp, acc_tp = model_tangent.evaluate(x_test, y_test, verbose=0)
print(f"TangentProp model accuracy: {acc_tp*100:.2f}%")

# --- Tangent-distance classifier (nearest neighbor) ---
y_pred = tangent_nn_classifier(x_train, y_train, x_test)
acc_td = np.mean(y_pred == y_test)
print(f"Tangent-distance classifier accuracy: {acc_td*100:.2f}%")

# --- Plot training loss for both methods ---
plt.plot(hist_adv.history['loss'], label='Adversarial Training Loss')
plt.plot(hist_tp.history['loss'], label='TangentProp Training Loss')
plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.title('Training Loss')
plt.grid(True); plt.show()