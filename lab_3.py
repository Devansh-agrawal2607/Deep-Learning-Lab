# -*- coding: utf-8 -*-
"""LAB 3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13J0yeD5QBJcgd6ivm5bByLQ17btrGu8L

Implement a program aimed at constructing and training a multilayer perceptron
tailored for a specific task, showcasing the execution of the backpropagation
algorithm. Construct a network with a linear input layer, Tanh or ReLU activation for
the hidden layers, and sigmoid or SoftMax activation for the output layer.
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# --- Load dataset ---
X, y = load_iris(return_X_y=True)

# --- Split into training and testing sets ---
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- Standardize features for better training ---
scaler = StandardScaler().fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

# --- Build MLP: input → hidden(ReLU/Tanh) → output(Sigmoid/Softmax) ---
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(X_train.shape[1],)),   # Input layer
    tf.keras.layers.Dense(64, activation='relu'),       # Hidden layer 1
    tf.keras.layers.Dense(32, activation='relu'),       # Hidden layer 2
    tf.keras.layers.Dense(16, activation='relu'),       # Hidden layer 3
    tf.keras.layers.Dense(3, activation='softmax')      # Output layer (Softmax for 3 classes)
])

# --- Compile model (defines loss + optimizer + metrics) ---
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# --- Train using backpropagation ---
history = model.fit(X_train, y_train, epochs=50, batch_size=32,
                    validation_split=0.1, verbose=1)

# --- Evaluate on test data ---
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test accuracy: {accuracy:.4f}")

# --- Plot accuracy curves ---
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='train')
plt.plot(history.history['val_accuracy'], label='validation')
plt.title('Model Accuracy'); plt.xlabel('Epoch'); plt.legend(); plt.grid(True)

# --- Plot loss curves ---
plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='validation')
plt.title('Model Loss'); plt.xlabel('Epoch'); plt.legend(); plt.grid(True)

plt.tight_layout()
plt.show()